[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html#quarto",
    "href": "posts/post-with-code/index.html#quarto",
    "title": "Yifei Chen",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1+1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "YC’s post",
    "section": "",
    "text": "Lab: Logistic Regression\n\n\nPrinceton University\n\n\n\n\n\n\n\n\nSuyog CHandramouli\n\n\n\n\n\n\n\n\n\n\n\n\nYifei Chen\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nYifei Chen\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 2, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html",
    "title": "Lab: Logistic Regression",
    "section": "",
    "text": "Assignment requirements:\n\nIf you are using Github (recommended), make sure to commit and push your work to GitHub regularly, at least after each exercise. Write short and informative commit messages, and share the link to your assignment with me. If not, you can also send me the rmd & rendered file via Canvas.\nIn this assignment, you will not need to code from scratch. Rather, you’ll need to fill in code where needed. This assignment has a logisitic regression implementation for a scenario from EDA down to model comparison (and would be useful for whenever you may encounter such a situation in the future).\nI want the assignments to begin reflecting a bit more of how you’d be doing things on your own, where you have some prior knowledge and you figure other things out (by referring to documentation, etc.) . In addition to the rmd, I also want you to submit to me notes of anything new that you learn while finishing the assignment. And any pain-points, and we’ll discuss more.\n\nNote:\n\nIf you are fitting a model, display the model output in a neatly formatted table. (The gt tidy and kable functions can help!). Modelsummary also looks good(https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html)\nMake sure that your plots are clearly labeled – for all axes, titles, etc."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#data-general-social-survey",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#data-general-social-survey",
    "title": "Lab: Logistic Regression",
    "section": "Data: General Social Survey",
    "text": "Data: General Social Survey\nThe General Social Survey (GSS) has been used to measure trends in attitudes and behaviors in American society since 1972. In addition to collecting demographic information, the survey includes questions used to gauge attitudes about government spending priorities, confidence in institutions, lifestyle, and many other topics. A full description of the survey may be found here.\nThe data for this lab are from the 2016 General Social Survey. The original data set contains 2867 observations and 935 variables. We will use and abbreviated data set that includes the following variables:\nnatmass: Respondent’s answer to the following prompt:\n“We are faced with many problems in this country, none of which can be solved easily or inexpensively. I’m going to name some of these problems, and for each one I’d like you to tell me whether you think we’re spending too much money on it, too little money, or about the right amount…are we spending too much, too little, or about the right amount on mass transportation?”\nage: Age in years.\nsex: Sex recorded as male or female\nsei10: Socioeconomic index from 0 to 100\nregion: Region where interview took place\npolviews: Respondent’s answer to the following prompt:\n“We hear a lot of talk these days about liberals and conservatives. I’m going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal - point 1 - to extremely conservative - point 7. Where would you place yourself on this scale?”\nThe data are in gss2016.csv in the data folder."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#eda",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#eda",
    "title": "Lab: Logistic Regression",
    "section": "EDA",
    "text": "EDA\n\nLet’s begin by making a binary variable for respondents’ views on spending on mass transportation. Create a new variable that is equal to “1” if a respondent said spending on mass transportation is about right and “0” otherwise. Then plot the proportion of the response variable, using informative labels for each category.\n\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(modelsummary)\nlibrary(tidyr)\nlibrary(knitr)\nlibrary(easystats)\nlibrary(broom)\nlibrary(emmeans)\nlibrary(marginaleffects)\nlibrary(performance)\nlibrary(arm)\nlibrary(modelsummary)\n\n\n\n\nCode\n# load data\ndata &lt;- read.csv(\"gss2016.csv\")\n\n\nFill in the “____” below to encode the binary variable\n\n\nCode\ndata &lt;- data %&gt;%\n   mutate(mass_trans_spend_right = ifelse(natmass == 'About right', 1, 0))\n\n\n\n\nCode\n#Get proportions\nmass_spend_summary &lt;- data %&gt;%\n  count(mass_trans_spend_right) %&gt;%\n  mutate(proportion = n / sum(n))\n\n#Look at the dataframe structure. And make sure it's in a format that you can use for plotting.\n#Change structure if neederd\nmass_spend_long &lt;- mass_spend_summary\n\n#Factorise for plot\nmass_spend_summary$mass_trans_spend_right &lt;- as.factor(mass_spend_summary$mass_trans_spend_right)\n\n# Step 3: Create the bar chart\nggplot(mass_spend_summary, aes(x = \"\", y = proportion, fill = mass_trans_spend_right)) +\n  geom_bar(stat = \"identity\") +  # Use identity to plot the actual proportions\n  labs(x = \"\", y = \"Proportion\", fill = \"Perception of Spending\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nRecode polviews so it is a factor with levels that are in an order that is consistent with question on the survey. Note how the categories are spelled in the data.\n\n\n\nCode\ndata &lt;- data %&gt;%\n  mutate(polviews = factor(polviews,\n                           levels = c(\"Extremely liberal\", \"Liberal\", \"Slightly liberal\", \"Moderate\", \"Slghtly conservative\", \"Conservative\", \"Extrmly conservative\"),\n                           ordered = TRUE))\n\n\n\nMake a plot of the distribution of polviews\n\n\n\nCode\nggplot(data, aes(x = polviews)) +\n  geom_bar() \n\n\n\n\n\n\n\n\n\n\nWhich political view occurs most frequently in this data set?\nModerate\n\n\nMake a plot displaying the relationship between satisfaction with mass transportation spending and political views. Use the plot to describe the relationship the two variables.\n\n\n\nCode\nggplot(data, aes(x = mass_trans_spend_right, fill = polviews)) +\n  geom_bar(position = \"fill\") +  # Position \"fill\" normalizes the bar height to 100%\n  labs(x = \"Satisfaction with Mass Transit Spending\", \n       y = \"Proportion\", \n       fill = \"Political Views\") +\n  theme_minimal() +\n  scale_y_continuous(labels = scales::percent) +  # Show y-axis as percentage\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels if necessary\n\n\n\n\n\n\n\n\n\nThe more conservative one’s political views are the more they think the amount of spending on mass transportation is correct.\n\nWe’d like to use age as a quantitative variable in your model; however, it is currently a character data type because some observations are coded as “89 or older”.\n\n\nRecode age so that is a numeric variable. Note: Before making the variable numeric, you will need to replace the values “89 or older” with a single value.\n\n\n\nCode\ndata &lt;- data %&gt;%\n  mutate(age = if_else(age == \"89 or older\", \"89\", age), \n         age = as.numeric(age))\n\n\n\nPlot the frequency distribution of age.\n\n\n\nCode\nggplot(data, aes(x = age)) +\n  geom_histogram()"
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#logistic-regression",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#logistic-regression",
    "title": "Lab: Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLet’s start by fitting a logistic regression model with just the intercept\n\n\n\nCode\nintercept_only_model &lt;- glm(\n  mass_trans_spend_right ~ 1,  \n  data = data,  \n  family = binomial()  \n)\n\nintercept_only_model %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.1190594\n0.0393685\n3.024229\n0.0024927\n\n\n\n\n\n\nInterpret the intercept in the context of the data. You can do this by converting the \\(\\beta_0\\) parameter out of the log-odds metric to the probability metric. Make sure to include the 95% confidence intervals. Then interpret the results in a sentence or two–what is the basic thing this probability tells us about?\n\n\n\nCode\nb0 &lt;- coef(intercept_only_model)[1] \n\nb0_transformed &lt;- exp(b0) / (1 + exp(b0)) \n\nci_lower = b0 - 1.96 * 0.0393685 \nci_upper = b0 + 1.96 * 0.0393685\n\np_lower = exp(ci_lower) / (1 + exp(ci_lower))\np_upper = exp(ci_upper) / (1 + exp(ci_upper)) \n\nc(b0, ci_lower, ci_upper)\n\n\n(Intercept) (Intercept) (Intercept) \n  0.1190594   0.0418971   0.1962216 \n\n\nInterpretation: There are more people who are satisfied with the mass transportation than not satisfy.\n\nNow let’s fit a model using the demographic factors - age,sex, sei10 - to predict the odds a person is satisfied with spending on mass transportation. Make any necessary adjustments to the variables so the intercept will have a meaningful interpretation. Neatly display the model coefficients (do not display the summary output)\n\n\n\nCode\n#make sure that sex is a factor (i.e. to make sure R knows it's binary/categorical, and not continuous)\ndata$sex &lt;- factor(data$sex, levels = c(\"Male\", \"Female\")) \n\n#fit with glm()\nmodel &lt;- glm(mass_trans_spend_right ~ age + sex + sei10, \n             data = data, \n             family = binomial()) \n\n#produce tidy output of model coefficients\nmodel %&gt;%\n  tidy() %&gt;%\n  kable() \n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.5697071\n0.1409061\n4.043169\n0.0000527\n\n\nage\n-0.0061659\n0.0022824\n-2.701502\n0.0069027\n\n\nsexFemale\n0.2557439\n0.0798020\n3.204732\n0.0013519\n\n\nsei10\n-0.0062271\n0.0016609\n-3.749229\n0.0001774\n\n\n\n\n\n\nConsider the relationship between sex and one’s opinion about spending on mass transportation. Interpret the coefficient of sex in terms of the logs odds and OR of being satisfied with spending on mass transportation. What are the predicted probabilities for males and females on support for spending on mass transportation? Please include the 95% CIs around each estimate.\n\n\n\nCode\nm1 &lt;- glm(mass_trans_spend_right ~ sex, \n             data = data, \n             family = binomial()) \n\nm1 %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.0254467\n0.0582517\n-0.4368402\n0.6622272\n\n\nsexFemale\n0.2661485\n0.0791791\n3.3613499\n0.0007756\n\n\n\n\n\nCode\nm1 %&gt;% \n  tidy(exponentiate = TRUE) %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.9748744\n0.0582517\n-0.4368402\n0.6622272\n\n\nsexFemale\n1.3049289\n0.0791791\n3.3613499\n0.0007756\n\n\n\n\n\nCode\nbsex &lt;- coef(m1)[\"sexFemale\"]\n\nci_lower_lo = bsex - 1.96 * 0.0791791\nci_upper_lo = bsex + 1.96 * 0.0791791\n\nci_lower_or = 1.29 - 1.96 * 0.0791791\nci_upper_or = 1.29 + 1.96 * 0.0791791\n\nemm_sex &lt;- emmeans(m1, \"sex\", type = \"response\")\nprint(c(bsex, ci_lower_or, ci_upper_or))\n\n\nsexFemale                     \n0.2661485 1.1348090 1.4451910 \n\n\nIf you did this right, you’ll find that being female (as compared to male) is associated with an increase in the log-odds of being satisfied with spending on mass transportation by 0.2557439 units (95% CI [0.09, 0.41]), holding all other variables constant. This equates to the odds of thinking the spending amount is right in females being 1.29 times the odds of thinking this in men (95% CI [1.13, 1.44]).\nThe predicted probability for females to be satisfied with spending on mass transportation is 55.9% (95% CI [53.3%, 58.5%]) and that of males is 49.5% (95% CI [46.7%, 52.4%]).\n\nVerify this.\n\nNext, consider the relationship between age and one’s opinion about spending on mass transportation. Interpret the coefficient of age in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate.\n\n\n\nCode\nm2 &lt;- glm(mass_trans_spend_right ~ age, \n             data = data, \n             family = binomial()) \n\nm2 %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.4540298\n0.1171726\n3.874879\n0.0001067\n\n\nage\n-0.0068425\n0.0022513\n-3.039332\n0.0023710\n\n\n\n\n\nCode\nm2 %&gt;% \n  tidy(exponentiate = TRUE) %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5746449\n0.1171726\n3.874879\n0.0001067\n\n\nage\n0.9931809\n0.0022513\n-3.039332\n0.0023710\n\n\n\n\n\nCode\nbage &lt;- coef(m2)[\"age\"]\n\nci_lower_lo = bage - 1.96 * 0.0022513   \nci_upper_lo = bage + 1.96 * 0.0022513   \n\nci_lower_or = exp(ci_lower_lo)\nci_upper_or = exp(ci_upper_lo)\n\nemm_age &lt;- emmeans(m2, \"age\", type = \"response\")\nprint(c(ci_lower_or, ci_upper_or))\n\n\n      age       age \n0.9888081 0.9975730 \n\n\nA one unit increase in age is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by 0.0068425, holding all other variables constant. The odds ratio is 0.9931809 which confirms the negative relationship implied by the log-odds coefficient. Specifically, for each additional unit of age, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.9931809, or approximately 0.068425% per unit increase in age, holding other factors constant.\n\nConsider the relationship between SES and one’s opinion about spending on mass transportation. Interpret the coefficient of SES in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate. ß\n\n\n\nCode\nm3 &lt;- glm(mass_trans_spend_right ~ sei10, \n             data = data, \n             family = binomial()) \n\nm3 %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.4458859\n0.0855874\n5.209716\n2.00e-07\n\n\nsei10\n-0.0070782\n0.0016410\n-4.313488\n1.61e-05\n\n\n\n\n\nCode\nm3 %&gt;% \n  tidy(exponentiate = TRUE) %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.5618733\n0.0855874\n5.209716\n2.00e-07\n\n\nsei10\n0.9929468\n0.0016410\n-4.313488\n1.61e-05\n\n\n\n\n\nCode\nbsei &lt;- coef(m3)[\"sei10\"]\nsei_se &lt;- summary(m3)$coefficients[\"sei10\", \"Std. Error\"]\n\nci_lower_lo = bsei - 1.96 * sei_se\nci_upper_lo = bsei + 1.96 * sei_se\n\nci_lower_or = exp(ci_lower_lo)\nci_upper_or = exp(ci_upper_lo)\n\nemm_age &lt;- emmeans(m3, \"sei10\", type = \"response\")\nprint(c(ci_lower_lo, ci_upper_lo, ci_lower_or, ci_upper_or))\n\n\n       sei10        sei10        sei10        sei10 \n-0.010294507 -0.003861966  0.989758300  0.996145482 \n\n\nA one unit increase in SES index is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by 0.0070782 units (95% CI [-0.010294507, -0.003861966]), holding all other variables constant. The odds ratio is less than 1 (0.9929468), which confirms the negative relationship implied by the log-odds coefficient. Specifically, for each additional unit of SES index, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.9929468, or approximately 0.7% per unit increase in SES index, holding other factors constant (95% CI [0.989758300, 0.996145482])."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#marginal-effects",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#marginal-effects",
    "title": "Lab: Logistic Regression",
    "section": "Marginal effects",
    "text": "Marginal effects\n\nLet’s examine the results on the probability scale.\n\n\nCalculate the marginal effects of sex, age, and SES on mass transportation spending. You can use the margins package function margins discussed in your textbook or you can use the marginaleffects package avg_slope avg_comparisons discussed in lecture. Interpret each estimate.\n\n\n\nCode\n# sex \navg_comparisons(m1, comparison = \"difference\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nestimate\nstd.error\nstatistic\np.value\ns.value\nconf.low\nconf.high\npredicted_lo\npredicted_hi\npredicted\n\n\n\n\nsex\nFemale - Male\n0.0662479\n0.0196632\n3.369125\n0.0007541\n10.37301\n0.0277087\n0.1047872\n0.4936387\n0.5598866\n0.4936387\n\n\n\n\n\nCode\n# age\navg_comparisons(m2, comparison = \"difference\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nestimate\nstd.error\nstatistic\np.value\ns.value\nconf.low\nconf.high\npredicted_lo\npredicted_hi\npredicted\n\n\n\n\nage\n+1\n-0.0016988\n0.0005551\n-3.06054\n0.0022094\n8.82214\n-0.0027867\n-0.0006109\n0.5330603\n0.5313568\n0.5330603\n\n\n\n\n\nCode\n# sei\navg_comparisons(m3, comparison = \"difference\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nestimate\nstd.error\nstatistic\np.value\ns.value\nconf.low\nconf.high\npredicted_lo\npredicted_hi\npredicted\n\n\n\n\nsei10\n+1\n-0.0017509\n0.0004002\n-4.375513\n1.21e-05\n16.33288\n-0.0025352\n-0.0009666\n0.456041\n0.4542857\n0.456041\n\n\n\n\n\n\nThe marginal effect of age is -0.0016988 (95% CI [-0.0027867, -0.0006109]). So, for each additional unit increase of age, the probability of being satisfied with mass transportation spending decreases by approximately 0.17 percentage points, holding other factors constant (p = 0.0022094).\nThe marginal effect of SES is -0.0017509 (95% CI [-0.0025352, -0.0009666]). For each one-unit increase in the socioeconomic index, the probability of being satisfied with mass transportation spending decreases by approximately 0.18 percentage points, holding other variables constant.\nThe marginal effect for being female compared to male is 0.0662479 (95% CI [0.0277087, 0.1047872]). This indicates that females are, on average, about 6.6 percentage points more likely than males to be satisfied with mass transportation spending, holding other factors constant."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-comparison",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-comparison",
    "title": "Lab: Logistic Regression",
    "section": "Model comparison",
    "text": "Model comparison\n\nNow let’s see whether a person’s political views has a significant impact on their odds of being satisfied with spending on mass transportation, after accounting for the demographic factors.\n\n\nConduct a drop-in-deviance/likelihood ratio test to determine if polviews is a significant predictor of attitude towards spending on mass transportation. Name these two models fit2 and fit3, respectively. Compare the two models.\n\n\n\nCode\nfit2 &lt;- glm(mass_trans_spend_right ~ sex + age + sei10, \n            data = data, \n            family = binomial())\n\nfit3 &lt;- glm(mass_trans_spend_right ~ sex + age + sei10 + polviews, \n            data = data, \n            family = binomial())\n\ntest_likelihoodratio(fit2, fit3) %&gt;% kable()\n\n\n\n\n\n\nName\nModel\ndf\ndf_diff\nChi2\np\n\n\n\n\nfit2\nfit2\nglm\n4\nNA\nNA\nNA\n\n\nfit3\nfit3\nglm\n10\n6\n63.02844\n0\n\n\n\n\n\n\nIs the model with polviews better than the model without?\n\n\nYes."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#visualization",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#visualization",
    "title": "Lab: Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\n\nLet’s plot the results\nWe next use the model to produce visualizations:\n\nGiven the code below, interpet what is being plotted:\n\npol_plot : ____\nsex_plot : ____\nses_plot: ___\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nadjust the various settings in your plot to make it look professional.\nYou can use ggeffects to get the predicted probabilities for these models.\n\n\n\n\n\n\nCode\nlibrary(ggeffects)\n\n\ncolors &lt;- c(\"Extremely liberal\" = \"black\",\n            \"Liberal\" = \"#0e2f44\",  # Dark blue\n            \"Slightly liberal\" = \"#1d5a6c\",  # Less dark blue\n            \"Moderate\" = \"#358ca3\",  # Medium blue\n            \"Slghtly conservative\" = \"#71b9d1\",  # Light blue\n            \"Conservative\" = \"#a6dcef\",  # Lighter blue\n            \"Extrmly conservative\" = \"#d0f0fd\")  # Very light blue\n\npp_pol &lt;- ggemmeans(fit3, terms = c(\"polviews\"))\n\n# Adjusted plot with gradient colors\npol_plot &lt;- ggplot(pp_pol, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  scale_color_manual(values = colors) +\n  labs(title = \"Effect of Political Views on Satisfaction with Mass Transportation\",\n       x = \"Political Views\", y = \"Predicted Probability\",\n       color = \"Political Views\") +\n  theme_minimal()\n\npol_plot\n\n\n\n\n\n\n\n\n\nCode\npp_sex &lt;- ggemmeans(fit3, terms = c(\"sex\"))\n\nsex_plot &lt;- ggplot(pp_sex, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  labs(title = \"Effect of Sex on Satisfaction with Mass Transportation\",\n       x = \"Sex\", y = \"Predicted Probability\",\n       color = \"Sex\") +\n  theme_minimal()\n\npp_sex\n\n\n# Predicted probabilities of mass_trans_spend_right\n\nsex    | Predicted |     95% CI\n-------------------------------\nMale   |      0.48 | 0.44, 0.51\nFemale |      0.55 | 0.51, 0.58\n\nAdjusted for:\n*   age = 48.90\n* sei10 = 46.07\n\n\nCode\npp_ses &lt;- ggemmeans(fit3, terms = \"sei10\")\n\n\nses_plot &lt;-  ggplot(pp_ses, aes(x = x, y = predicted)) +\n  geom_line(color = \"#2c7fb8\", size = 1) + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = \"#2c7fb8\", alpha = 0.2) +  # Add a confidence interval band\n  labs(title = \"Effect of SES on Satisfaction with Mass Transportation\",\n       x = \"Socioeconomic Status\", y = \"Predicted Probability\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")  \nses_plot"
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-assumptions",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-assumptions",
    "title": "Lab: Logistic Regression",
    "section": "Model Assumptions",
    "text": "Model Assumptions\n\nIs the logistic model a good choice for this data?\n\n\n\nCode\nbinned_residuals(fit2)\n\n\nWarning: About 86% of the residuals are inside the error bounds (~95% or higher would be good).\n\n\n\n\n\n\n\n\nNote\n\n\n\nAnswer: It is below 95%, so not really a good choice."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-fit",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#model-fit",
    "title": "Lab: Logistic Regression",
    "section": "Model fit",
    "text": "Model fit\n\nCalculate the \\(R^2\\) for this model\n\n\n\nCode\nr2_mcfadden(fit2)\n\n\n# R2 for Generalized Linear Regression\n       R2: 0.010\n  adj. R2: 0.009\n\n\n\nR2 interpretation: Only one percent of the variation is accounted by the model, so not a good model.\nNext, Take a look at the binned residual plots for each continuous predictor variable and look at linearity. Is there a predictor that sticks out? What can we do to improve model fit in this case?\n\n\n\nCode\nbinned_residuals(fit2, term=\"sei10\")\n\n\nWarning: About 88% of the residuals are inside the error bounds (~95% or higher would be good).\n\n\nCode\nbinned_residuals(fit2, term=\"age\")\n\n\nOk: About 98% of the residuals are inside the error bounds.\n\n\nCode\nbinned_residuals(fit2, term=\"sei10\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\nCode\nbinned_residuals(fit2, term=\"age\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe sei10 doesn’t seems to be a good predictors since there are more residuals that fall outside of the error bounds and the residuals look less random compared to age. Perhaps transforming the sei10 values can help to make the residuals look more random/less systematic."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#testing-polviews",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#testing-polviews",
    "title": "Lab: Logistic Regression",
    "section": "Testing Polviews",
    "text": "Testing Polviews\n\n\nCode\nemmeans(fit3, \"polviews\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n\n contrast                                   estimate        SE  df z.ratio\n Extremely liberal - Moderate             -0.9266262 0.1950664 Inf  -4.750\n Extremely liberal - Slghtly conservative -0.8487137 0.2127293 Inf  -3.990\n Extremely liberal - Conservative         -0.9935486 0.2108369 Inf  -4.712\n Extremely liberal - Extrmly conservative -1.3402621 0.2792876 Inf  -4.799\n Liberal - Moderate                       -0.7090022 0.1308520 Inf  -5.418\n Liberal - Slghtly conservative           -0.6310897 0.1555805 Inf  -4.056\n Liberal - Conservative                   -0.7759246 0.1532081 Inf  -5.065\n Liberal - Extrmly conservative           -1.1226380 0.2392048 Inf  -4.693\n Slightly liberal - Extrmly conservative  -0.7334002 0.2412625 Inf  -3.040\n p.value\n  &lt;.0001\n  0.0013\n  0.0001\n  &lt;.0001\n  &lt;.0001\n  0.0010\n  &lt;.0001\n  0.0001\n  0.0382\n\nResults are averaged over the levels of: sex \nResults are given on the log odds ratio (not the response) scale. \nP value adjustment: tukey method for comparing a family of 7 estimates \n\n\nCode\nemmeans(fit3, \"polviews\", type=\"response\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n\n contrast                                 odds.ratio         SE  df null\n Extremely liberal / Moderate              0.3958871 0.07722426 Inf    1\n Extremely liberal / Slghtly conservative  0.4279651 0.09104070 Inf    1\n Extremely liberal / Conservative          0.3702605 0.07806458 Inf    1\n Extremely liberal / Extrmly conservative  0.2617771 0.07311109 Inf    1\n Liberal / Moderate                        0.4921350 0.06439684 Inf    1\n Liberal / Slghtly conservative            0.5320118 0.08277063 Inf    1\n Liberal / Conservative                    0.4602780 0.07051835 Inf    1\n Liberal / Extrmly conservative            0.3254202 0.07784206 Inf    1\n Slightly liberal / Extrmly conservative   0.4802732 0.11587191 Inf    1\n z.ratio p.value\n  -4.750  &lt;.0001\n  -3.990  0.0013\n  -4.712  0.0001\n  -4.799  &lt;.0001\n  -5.418  &lt;.0001\n  -4.056  0.0010\n  -5.065  &lt;.0001\n  -4.693  0.0001\n  -3.040  0.0382\n\nResults are averaged over the levels of: sex \nP value adjustment: tukey method for comparing a family of 7 estimates \nTests are performed on the log odds ratio scale \n\n\n\nConservatives are 1/0.3702605 and 1/0.4602780 times more likely to support mass transit spending compared to extremely liberal and liberal\nExtreme liberals are 0.3702605, 0.3958871, and 0.4279651 times more likely to support spending compared to conservatives, moderates and slight conservatives\nExtrm conservatives are 1/0.3254202 and 1/0.4802732 times more likely to support mass spending than liberals and slight liberals\nLiberals are 0.4921350 and 0.5320118 times more likely to support spending than moderates and slight conservatives."
  },
  {
    "objectID": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#conclusion",
    "href": "posts/Lab_Logistic_Regression/Lab: Logistic Regression.html#conclusion",
    "title": "Lab: Logistic Regression",
    "section": "Conclusion",
    "text": "Conclusion\nPolitical view is probably the best predictor in our case since the data itself falls more into a logistic regression patterns compared to sex, where things are binary and not continuous, and socioeconomic status, where things are linear based on the model summary below, and the three figures.\n\n\n\n\nDf\nDeviance\nResid. Df\nResid. Dev\nPr(&gt;Chi)\n\n\n\n\nNULL\nNA\nNA\n2589\n3581.340\nNA\n\n\nsex\n1\n11.31903\n2588\n3570.021\n0.0007672\n\n\nage\n1\n10.10603\n2587\n3559.915\n0.0014778\n\n\nsei10\n1\n14.11908\n2586\n3545.796\n0.0001716\n\n\npolviews\n6\n63.02844\n2580\n3482.768\n0.0000000\n\n\n\nTable 1\n\n\n\n\n\nFigure 1: Effect of Sex on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 2: Effect of SES on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 3: Effect of Political Views on Satisfaction with Mass Transportation"
  }
]