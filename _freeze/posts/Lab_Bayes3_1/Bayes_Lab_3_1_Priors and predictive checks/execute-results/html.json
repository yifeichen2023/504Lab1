{
  "hash": "f52b28d33580a1bf088b7422d62d5137",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"PSY 504: Bayes Lab 3, Priors and Predictive Checks April 16th, 2025\"\nformat: html\neditor: visual\n---\n\n\n\n\\\nDuring the first Bayes Lab you considered exploratory data analysis, compared default brms with lm(), and extracted posteriors after fitting models. You summarized posterior distributions and also generated a distribution of predictions using these posterior draws.\\\n\\\nDuring the second Bayes lab, you looked at the different types of distributions that are relevant for Bayesian analysis, including priors.\n\nDuring today's lab, you will go into prior predictive checks and some HMC diagnostics. While we look at the simple linear modeling case, this workflow is relevant for all Bayesian models.\n\n## Setup: Packages and data\n\nLoad the primary packages.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n# library(truncnorm)  # if needed\n```\n:::\n\n\n\nThis time we'll be taking data from the **moderndive** package. We want the `evals` data set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(evals, package = \"moderndive\")\n```\n:::\n\n\n\nThe `evals` data were originally in the paper by Hamermesh and Parker (2005; <https://doi.org/10.1016/j.econedurev.2004.07.013).> You can learn more about the data like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?moderndive::evals\n```\n:::\n\n\n\nYou can learn even more information about the data from <https://www.openintro.org/data/index.php?data=evals.>\n\nAnyway, we need to subset the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals94 <- evals %>% \n  group_by(prof_ID) %>% \n  slice(1) %>% \n  ungroup()\n\nglimpse(evals94)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 94\nColumns: 14\n$ ID           <int> 1, 5, 8, 10, 18, 24, 31, 36, 43, 50, 60, 63, 68, 75, 79, …\n$ prof_ID      <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ score        <dbl> 4.7, 4.6, 4.1, 4.5, 4.8, 4.4, 4.4, 3.4, 4.8, 4.0, 3.6, 4.…\n$ age          <int> 36, 59, 51, 40, 31, 62, 33, 51, 33, 47, 35, 37, 42, 49, 3…\n$ bty_avg      <dbl> 5.000, 3.000, 3.333, 3.167, 7.333, 5.500, 4.167, 4.000, 4…\n$ gender       <fct> female, male, male, female, female, male, female, female,…\n$ ethnicity    <fct> minority, not minority, not minority, not minority, not m…\n$ language     <fct> english, english, english, english, english, english, eng…\n$ rank         <fct> tenure track, tenured, tenured, tenured, tenure track, te…\n$ pic_outfit   <fct> not formal, not formal, not formal, not formal, not forma…\n$ pic_color    <fct> color, color, color, color, color, color, color, color, c…\n$ cls_did_eval <int> 24, 17, 55, 40, 42, 182, 33, 25, 48, 16, 18, 30, 28, 30, …\n$ cls_students <int> 43, 20, 55, 46, 48, 282, 41, 41, 60, 19, 25, 34, 40, 36, …\n$ cls_level    <fct> upper, upper, upper, upper, upper, upper, upper, upper, u…\n```\n\n\n:::\n:::\n\n\n\n## Intercept-only model\n\nLet's start by fitting an intercept-only model\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 \\\\\n\\beta_0 & \\sim \\text{???} \\\\\n\\sigma & \\sim \\text{???},\n\\end{align} \n$$\n\nwhere $\\beta_0$ is the same as the unconditional population mean, and the population standard deviation is $\\sigma$. Our next task will be choosing our priors.\n\n#### Question 1: Why have we left some of the specification above unfilled / with questions marks at this point?\n\nBecause we still need to figure out what is the appropriate priors for this data set in order to have a proper model working.\n\n### Visualize possible prior distributions.\n\nIn this exercise, we'll choose the priors together. Let's start with prior on $\\beta_0$. Below are a few candidate distributions visualized with **ggdist** and friends.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\n  prior(normal(5.5, 1)),\n  prior(normal(8, 2)),\n  prior(normal(5.5, 2))\n) %>% \n  parse_dist() %>% \n\n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  labs(subtitle = \"The red lines mark the lower and upper boundaries.\",\n       x = expression(italic(p)(beta[0])),\n      y = NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nThe red lines in the figures (shown at x=1 and x=10) represent the lower and upper boundaries for the beauty ratings scale used in the study. With the simple intercept model, setting a prior on the intercept parameter is the same as setting a prior on the expected mean in observation space.\n\nNow let's visualize a few potential priors for $\\sigma$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\n  prior(exponential(1)), \n  prior(normal(0, 1), lb = 0), \n  prior(normal(2, 0.3), lb = 0)\n) %>% \n  parse_dist() %>% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  xlab(expression(italic(p)(sigma))) +\n  ylab(NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n#### Question 2: Given that $\\sigma$ refers to the standard deviation, are these three priors theoretically possible? If yes, give an example of a theoretically impossible prior for $\\sigma$.\n\nThey are all theoretically possible since all of them are bounded and they are all greater than 0. Anything that can go to negative will be impossible.\n\n### Prior-predictive checks (by hand).\n\nNote: It's possible we'll need the `truncnorm::rtruncnorm()` function in this section. Once we have candidate priors for both $\\beta_0$ and $\\sigma$, we can simulate values from those priors and plot the implied distributions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the simulation reproducible?\n# set.seed(1)\n\n# simulate values from the priors\ntibble(iter = 1:n,\n       # choose the hyperparameter values with the class\n       beta0 = rnorm(n = n, mean = 5.5, sd = 1),\n       sigma = rexp(n = n, rate = 1 / 1)) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  mutate(density = dnorm(x = bty_avg, mean = beta0, sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nThe simulated values constitute predictions that are made using our prior beliefs (a prior is set for beta0 and another for sigma) When you check if these predictions (prior predictive) make sense or not, it is called the prior predictive check. The point of the prior predictive check is to iterate on specifying the priors until the prior predictive is sensible/satisfactory.\n\n(Again, the red boundaries denote that the only possible bty_avg values are between 1 and 10.)\n\n#### Question 3: Can Explain what the section of the previous command, before ggplot is doing?\n\n50 independent simulations, with beta 0 generating from Normal(5.5, 1) and sigma generating from exp(1). Beta0 serves as the mean and sigma serves as the SD of individual new normal dist simulation on the range of seq(from = -2, to = 13, by = 0.025).\n\n#### Question 4: The prior predictive above is for one combination of our candidate priors. Why don't you also try the $\\beta_0$ prior centered at 8, along with the $\\sigma$ prior centered at 2? What do you observe? Among these two , which would you pick? And why? (Optional: try others too if you'd like)\n\nIf we have prior centered at 8 with sigma centered at 2 then the distribution is going to shift to the right hand side (more positive) and more spread out (wider range). I would pick the first one since the range of the values fit more into the 1 to 10 range of the actual data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the simulation reproducible?\n# set.seed(1)\n\n# simulate values from the priors\ntibble(iter = 1:n,\n       # choose the hyperparameter values with the class\n       beta0 = rnorm(n = n, mean = 8, sd = 2),\n       sigma = rnorm(n = n, mean = 2, sd = 0.3)) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  mutate(density = dnorm(x = bty_avg, mean = beta0, sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n### Fit the model that you prefer\n\nWe should practice writing out our model equation with our priors of choice:\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 \\\\\n\\beta_0 & \\sim \\operatorname{Normal}(5.5, 1) \\\\\n\\sigma & \\sim \\operatorname{Exp}(1).\n\\end{align}\n$$\n\nLet's fit a model with our priors of choice.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit9.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 1,\n  # make sure we're settled on our priors \n  # we don't need to use these; they're placeholders\n  prior = prior(normal(5.5, 1), class = Intercept) +\n    prior(exponential(1), class = sigma)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\n\nCheck the model summary.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit9.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 1 \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.63      0.16     4.31     4.95 1.00     3159     2456\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.60      0.12     1.39     1.85 1.00     3312     2503\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nNow we might do a posterior predictive check to see how well our model describes the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit9.b, ndraws = 100) +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit9.b, ndraws = 8,\n         type = \"hist\", binwidth = 0.5) +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\")  +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n\n\nOur simple Gaussian model doesn't do a great job respecting the lower and upper boundaries, but this is about as good as it gets when you're in Gaussian land. On the whole, the model did a pretty okay reproducing the gross features of the distribution of the sample data.\n\n#### Question 5: To ensure you've understood things well, can you write below about the difference between the prior predictive check and the posterior predictive check? How do they differ in their objectives?\n\nPrior predictive check is to check whether the prior we have is reasonable, i.e., whether it leads to reasonable prediction of the actual data. Posterior predictive check is more like, after fitting the model, whether the model fits well to the actual data. I guess for prior predictive check, we do it before we fit the model, and for posterior predictive check, we do it after we fit the model.\n\n## Prior-predictive checks (by `sample_prior = \"only\"`)\n\nWe can also sample from the prior predictive distribution from `brm()` itself. To do so, we use the `sample_prior` argument, which has the following options:\n\n-   `\"no\"`, which is the default, and does not sample from the prior;\n-   `\"yes\",`, which will sample from both the prior and the posterior; and\n-   `\"only\"`, which will only sample from the prior.\n\nLet's set `sample_prior = \"only\"`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit10.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 1,\n  prior = prior(normal(5.5, 1), class = Intercept) +\n    prior(exponential(1), class = sigma),\n  # here's the magic\n  sample_prior = \"only\",\n  # we can set our seed, too!\n  seed = 1\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\n\nDid you notice how we used the `seed` argument? This makes the results reproducible.\n\nNow the `summary()` function only returns summaries for the priors, NOT the posterior.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit10.b)  # this summarizes the prior\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 1 \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     5.50      1.00     3.61     7.49 1.00     1876     1938\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.00      1.01     0.03     3.63 1.00     1957     1424\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nThe `as_draws_df()` function also returns draws from the prior.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas_draws_df(fit10.b) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 6 iterations, 1 chains, and 5 variables\n  b_Intercept sigma Intercept lprior lp__\n1         5.5  0.80       5.5   -1.7 -1.9\n2         4.8  1.36       4.8   -2.5 -2.2\n3         4.4  0.46       4.4   -2.0 -2.8\n4         6.1  0.72       6.1   -1.8 -2.1\n5         5.5  1.13       5.5   -2.0 -1.9\n6         5.7  1.51       5.7   -2.4 -2.0\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\n\nHere's how we might use that `as_draws_df()` output to make a similar plot to the one we made before.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the results reproducible?\n# set.seed(1)\n\nas_draws_df(fit10.b) %>% \n  \n  # subset\n  slice_sample(n = n) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  # notice we're defining the mean by b_Intercept\n  mutate(density = dnorm(x = bty_avg, mean = b_Intercept, sd = sigma)) %>% \n  \n  ggplot(aes(x = bty_avg, y = density, \n             # notice we're grouping by .draw\n             group = .draw)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nWe can also use functions like `pp_check()` to compare the prior to the sample data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit10.b, ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit10.b, ndraws = 8,\n         type = \"hist\", binwidth = 0.5) +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n\n## Univariable predictor model\n\nNow we'll add `gender` as the sole predictor in the model,\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{gender}_i \\\\\n\\beta_0 & \\sim \\text{???} \\\\\n\\beta_1 & \\sim \\text{???} \\\\\n\\sigma & \\sim \\text{???}.\n\\end{align}\n$$\n\nLet's try these same set of $\\beta_0$ priors\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# change as needed\n\nc(\n  prior(normal(5.5, 1)),\n  prior(normal(7, 0.5)),\n  prior(normal(5.5, 2))\n) %>% \n  parse_dist() %>% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  labs(subtitle = \"The red lines mark the lower and upper bondaries.\",\n       x = expression(italic(p)(beta[0])),\n      y = NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\nNow we update our by-hand prior predictive simulation to accomodate $\\beta_0$ and $\\beta_1$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 50\n\nset.seed(1)\n\ntibble(iter = 1:n,\n       beta0 = rnorm(n = n, mean = 5.5, sd = 1),\n       # notice our new line\n       beta1 = rnorm(n = n, mean = 0, sd = 1),\n       sigma = rexp(n = n, rate = 1 / 1)) %>% \n  # we have a new expand_grid() line\n  # make sure everyone understands this coding scheme\n  expand_grid(gendermale = 0:1) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  # notice the updated mean formula\n  mutate(density = dnorm(x = bty_avg, \n                         mean = beta0 + beta1 * gendermale, \n                         sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~ and~italic(p)(beta[1])~and~italic(p)(sigma))) +\n  facet_wrap(~ gendermale, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\nBefore we fit the model, let's practice the `sample_prior = \"only\"` approach.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit11.b = brm(\n  data = evals94,\n  family = gaussian,\n  # notice the 0 + Intercept syntax\n  bty_avg ~ 0 + Intercept + gender,\n  prior = prior(normal(5.5, 1), class = b, coef = Intercept) +\n    prior(normal(0, 1), class = b, coef = gendermale) +\n    prior(exponential(1), class = sigma),\n  # here's the magic\n  sample_prior = \"only\",\n  seed = 2\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\n\nCheck the prior summary.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit11.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 0 + Intercept + gender \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      5.46      1.00     3.53     7.43 1.00     3147     2820\ngendermale     0.02      0.99    -1.91     1.99 1.00     4109     2946\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.02      0.98     0.03     3.66 1.00     3149     1903\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nCompare the prior with the data with `pp_check()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit11.b, \n         type = \"dens_overlay_grouped\",\n         group = \"gender\",\n         ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit11.b, ndraws = 5,\n         type = \"freqpoly_grouped\", group = \"gender\") +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\n\n\nThere isn't a great grouped histogram option for `pp_check()`, so we experimented with `type = \"freqpoly_grouped\"` instead.\n\nIf we wanted, we could also use the `predict()` function to simulate `bty_avg` values from the priors.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# walk through this slowly\n\nset.seed(1)\n\npredict(fit11.b,\n        summary = FALSE,\n        ndraws = 5) %>% \n  str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n num [1:5, 1:94] 5.37 7.82 3.87 4.89 6.06 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : NULL\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# customize the predictor grid, as desired\nnd <- tibble(gender = rep(c(\"female\", \"male\"), each = 50)) %>% \n  # this will make it easier to connect the nd data to the predict() output\n  mutate(row = 1:n())\n\nset.seed(1)\n\npredict(fit11.b,\n        newdata = nd,\n        summary = FALSE,\n        ndraws = 5) %>% \n  data.frame() %>% \n  mutate(draw = 1:n()) %>% \n  pivot_longer(-draw) %>% \n  mutate(row = str_remove(name, \"X\") %>% as.double()) %>% \n  left_join(nd, by = \"row\") %>% \n  \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 0.5, boundary = 1) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  facet_grid(draw ~ gender, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\nOnce we've settled on our priors, we should once again practice writing out the full model equation:\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{gender}_i \\\\\n\\beta_0 & \\sim \\operatorname{Normal}(5.5, 1) \\\\\n\\beta_1 & \\sim \\operatorname{Normal}(0, 1) \\\\\n\\sigma & \\sim \\operatorname{Exp}(1).\n\\end{align}\n$$\n\nOkay, let's fit the real model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit12.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 0 + Intercept + gender,\n  prior = prior(normal(5.5, 1), class = b, coef = Intercept) +\n    prior(normal(0, 1), class = b, coef = gendermale) +\n    prior(exponential(1), class = sigma),\n  \n  # yes, you can set your seed for your posteriors, too\n  # this makes the results reproducible\n  seed = 3\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nTrying to compile a simple C file\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\n\nCheck the model summary.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit12.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 0 + Intercept + gender \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      4.93      0.24     4.48     5.40 1.00     2134     2345\ngendermale    -0.54      0.31    -1.14     0.06 1.00     2050     2218\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.59      0.12     1.38     1.83 1.00     2431     2371\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nHow does the posterior-predictive check look?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit12.b, \n         type = \"dens_overlay_grouped\",\n         group = \"gender\",\n         ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12)) +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit12.b, ndraws = 5,\n         type = \"freqpoly_grouped\", group = \"gender\") +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-22-2.png){width=672}\n:::\n:::\n\n\n\n#### Question 6: Does the posterior predictive check look satisfactory to you?\n\nIt looks good since they overlay with each other on the density plot but I am not sure whether it captures the potential small gender difference in the actual data (when we look at the male data).\n\n::: callout-note\nFor more on prior predictive checks, see McElreath (from Chapter 4), and Solomon Kurz's brms/tidverse implementations as well.\n\nFor a comprehensive guide to set priors for a given situation, look at reccomendations made by the Stan team https://github.com/stan-dev/stan/wiki/prior-choice-recommendations\n\nThey generally recommend against uniform priors on $\\beta$ and $\\sigma$ parameters. This is based on a general principle that you should not use a prior that places an artificial boundary on a parameter.\n\nE.g. $\\sigma$ parameters have natural lower boundaries at zero, but they don't have upper boundaries. Thus, a uniform prior adds an unnatural upper boundary. A better prior would be something that is weakly informative\n:::\n\n## References\n\nHamermesh, D. S., & Parker, A. (2005). Beauty in the classroom: Instructors' pulchritude and putative pedagogical productivity. *Economics of Education Review, 24*(4), 369-376. https://doi.org/10.1016/j.econedurev.2004.07.013\n\nKurz, A. S. (2023). *Statistical Rethinking with brms, ggplot2, and the tidyverse: Second Edition* (version 0.4.0). https://bookdown.org/content/4857/\n\nMcElreath, R. (2020). *Statistical rethinking: A Bayesian course with examples in R and Stan* (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\n\n## Session information\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Ventura 13.5.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] tidybayes_3.0.7 brms_2.22.0     Rcpp_1.0.14     lubridate_1.9.4\n [5] forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4     purrr_1.0.4    \n [9] readr_2.1.5     tidyr_1.3.1     tibble_3.2.1    ggplot2_3.5.2  \n[13] tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6         tensorA_0.36.2.1     QuickJSR_1.7.0      \n [4] xfun_0.51            htmlwidgets_1.6.4    processx_3.8.6      \n [7] inline_0.3.21        lattice_0.22-6       callr_3.7.6         \n[10] tzdb_0.5.0           numDeriv_2016.8-1.1  ps_1.9.0            \n[13] vctrs_0.6.5          tools_4.4.3          generics_0.1.3      \n[16] curl_6.2.1           stats4_4.4.3         parallel_4.4.3      \n[19] pkgconfig_2.0.3      Matrix_1.7-2         checkmate_2.3.2     \n[22] distributional_0.5.0 RcppParallel_5.1.10  lifecycle_1.0.4     \n[25] farver_2.1.2         compiler_4.4.3       Brobdingnag_1.2-9   \n[28] munsell_0.5.1        codetools_0.2-20     htmltools_0.5.8.1   \n[31] bayesplot_1.11.1     yaml_2.3.10          pillar_1.10.1       \n[34] arrayhelpers_1.1-0   StanHeaders_2.32.10  bridgesampling_1.1-2\n[37] abind_1.4-8          nlme_3.1-167         rstan_2.32.7        \n[40] posterior_1.6.1      tidyselect_1.2.1     digest_0.6.37       \n[43] svUnit_1.0.6         mvtnorm_1.3-3        stringi_1.8.4       \n[46] reshape2_1.4.4       labeling_0.4.3       fastmap_1.2.0       \n[49] grid_4.4.3           colorspace_2.1-1     cli_3.6.4           \n[52] magrittr_2.0.3       loo_2.8.0            pkgbuild_1.4.7      \n[55] withr_3.0.2          scales_1.3.0         backports_1.5.0     \n[58] timechange_0.3.0     estimability_1.5.1   rmarkdown_2.29      \n[61] matrixStats_1.5.0    emmeans_1.11.0       gridExtra_2.3       \n[64] hms_1.1.3            coda_0.19-4.1        evaluate_1.0.3      \n[67] knitr_1.50           V8_6.0.2             ggdist_3.3.2        \n[70] rstantools_2.4.0     rlang_1.1.5          glue_1.8.0          \n[73] rstudioapi_0.17.1    jsonlite_1.9.1       plyr_1.8.9          \n[76] R6_2.6.1            \n```\n\n\n:::\n:::\n",
    "supporting": [
      "Bayes_Lab_3_1_Priors-and-predictive-checks_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}