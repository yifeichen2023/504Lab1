{
  "hash": "e8df23c182800859bfdf462423c347d6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intro to MLM Exercise/Walkthrough\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n\n\n::: {.callout-note collapse=\"false\"}\n#### New Packages!\n\nThese are the main packages we're going to use in this block. It might\nmake sense to install them now *if you do not have them already*\n\n-   **tidyverse** : for organising data\\\n-   **lme4** : for fitting generalised linear mixed effects models\n-   **broom.mixed** : tidying methods for mixed models\n-   **effects** : for tabulating and graphing effects in linear models\n-   **lmerTest**: for quick p-values from mixed models\n-   **parameters**: various inferential methods for mixed models\n:::\n\n# Getting to grips with MLM\n\n::: lo\nThese exercises are not \"how to do analyses with multilevel models\" -\nthey are designed to get you thinking, and help with an understanding of\nhow these models work.\n:::\n\n::::::: frame\n**Data: New Toys!**\n\nLet's consider a linear regression scenario with a toy dataset. Analysis\nquestion: How does practice influences the reading age of toy characters\nDataset link: <https://uoepsy.github.io/data/toy2.csv> contains\ninformation on 129 different toy characters that come from a selection\nof different families/types of toy.\n\nYou can see the variables in the table below[^1].\\\n<br>\n\n:::::: columns\n::: {.column width=\"45%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/toys.png){fig-align='center' width=300px}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"10%\"}\n:::\n\n::: {.column width=\"45%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"boezqdscwb\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#boezqdscwb table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#boezqdscwb thead, #boezqdscwb tbody, #boezqdscwb tfoot, #boezqdscwb tr, #boezqdscwb td, #boezqdscwb th {\n  border-style: none;\n}\n\n#boezqdscwb p {\n  margin: 0;\n  padding: 0;\n}\n\n#boezqdscwb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#boezqdscwb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#boezqdscwb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#boezqdscwb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#boezqdscwb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#boezqdscwb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#boezqdscwb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#boezqdscwb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#boezqdscwb .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#boezqdscwb .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#boezqdscwb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#boezqdscwb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#boezqdscwb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#boezqdscwb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#boezqdscwb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#boezqdscwb .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#boezqdscwb .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#boezqdscwb .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#boezqdscwb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#boezqdscwb .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#boezqdscwb .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#boezqdscwb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#boezqdscwb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#boezqdscwb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#boezqdscwb .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#boezqdscwb .gt_left {\n  text-align: left;\n}\n\n#boezqdscwb .gt_center {\n  text-align: center;\n}\n\n#boezqdscwb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#boezqdscwb .gt_font_normal {\n  font-weight: normal;\n}\n\n#boezqdscwb .gt_font_bold {\n  font-weight: bold;\n}\n\n#boezqdscwb .gt_font_italic {\n  font-style: italic;\n}\n\n#boezqdscwb .gt_super {\n  font-size: 65%;\n}\n\n#boezqdscwb .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#boezqdscwb .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#boezqdscwb .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#boezqdscwb .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#boezqdscwb .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#boezqdscwb .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#boezqdscwb .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#boezqdscwb .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#boezqdscwb div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">toy_type</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Type of Toy</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">year</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Year Released</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">toy</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Character</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">hrs_week</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Hours of practice per week</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">R_AGE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Reading Age</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n:::\n::::::\n:::::::\n\n[^1]: Image\n    sources:<br>http://tophatsasquatch.com/2012-tmnt-classics-action-figures/<br>https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/<br>https://www.wish.com/product/5da9bc544ab36314cfa7f70c<br>https://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asp<br>https://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.html<br>https://tvtropes.org/pmwiki/pmwiki.php/Toys/Furby<br>https://www.fun.com/toy-story-4-figure-4-pack.html<br>https://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n Below is some code that fits a model of \"reading\nage\" (`R_AGE`) predicted by hours of practice (`hrs_week`). Line 2 then\ngets the 'fitted' values from the model and adds them as a new column to\nthe dataset, called `pred_lm`. The fitted values are what the model\npredicts for every individual observation (every individual toy in our\ndataset).\n\nLines 4-7 then plot the data, split up by each type of toy, and adds\nlines showing the model fitted values.\n\nRun the code and check that you get a plot. What do you notice about the\nlines?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n:::\n\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#YOUR ATTEMPT HERE\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=80%}\n:::\n\n```{.r .cell-code}\n# the problem with the current fit is that we fit one model across different toy types without considering how each toy type may have affected the relationship between the practice time and the reading age. Perhaps fit individual model on each type of toy will better capture the true relationship.\n```\n:::\n\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-1' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-1', 'sol-start-1')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-1\" style=\"display: none;\">\n\n\n\nWe should get something like this:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nNote that the lines are exactly the same for each type of toy. This\nmakes total sense, because the model (which is where we've got the lines\nfrom) completely *ignores* the `toy_type` variable!\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#\n```\n:::\n\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\n\nBelow are 3 more code chunks that all 1) fit a model, then 2) add the\nfitted values of that model to the plot.\n\nThe first model is a 'no-pooling' approach, where we use tools learned\nin USMR and simply add in `toy_type` as a predictor in the model to\nestimate all the differences between types of toys.\n\nThe second and third are multilevel models. The second fits random\nintercepts by-toytype, and the third fits random intercepts and slopes\nof `hrs_week`\n\nCopy each chunk and run through the code. Pay attention to how the lines\ndiffer.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(lme4)\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n:::\n\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#ENTER YOUR ATTEMPT AND THOUGHTS HERE:\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n```\n:::\n\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-2' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\n\nThe first model has an adjustment for each toy-type (we can see this in\nthe coefficients if we want). What this means is that the line for each\ntype of toy is shifted up or down. We can see that the lines are now\nshifted up for things like \"Scooby Doo\" and \"G.I.Joe\", and down for\n\"transformers\" and \"farm animals\":\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nThis next one *looks* very similar to the previous one, but it is\nconceptually doing something a bit different. Rather than separating out\nand estimating differences between all the toy-types, we are modelling\n*a distribution* of deviations for each type from some average.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nFinally, we can add in the random slopes of `hrs_week`. In this model,\nwe are not only allowing toy-types to vary in their average reading age\n(i.e. shifting lines up and down), but we are also allowing them to vary\nin the association between hrs_week and reading age (letting the lines\nhave different slopes). Some types of toy (Scooby Doo, Sock Puppets,\nStretch Armstrong) have fairly positive slopes, and some have a flatter\nassociation (e.g, SuperZings etc).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#ENTER TLDR ON HOW YOUR ANSWER DIFFERED FROM THE SOLUTIONS\n# the answer i have for question 1 matches with the third approach where it allows more flaxibility to the model by accounting difference between toy types and fit different slopes and intercept (more flexible model) across different toy types.\n\n\n#... CONTINUE THIS WAY THROUGH THE ASSIGNMENT\n```\n:::\n\n\n\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\n\nFrom the previous questions you should have a model called `ri_mod`.\n\nBelow is a plot of the fitted values from that model. Rather than having\na separate facet for each type of toy as we did above, I have put them\nall on one plot. The thick black line is the average intercept and slope\nof the toy-type lines.\n\nIdentify the parts of the plot that correspond to A1-4 in the summary\noutput of the model below\n\n::::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/match_summ1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n:::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from these options:\n\n-   where the black line cuts the y axis (at x=0)\\\n-   the slope of the black line\\\n-   the standard deviation of the distances from all the individual\n    datapoints (toys) to their respective toy-type lines\\\n-   the standard deviation of the distances from all the toy-type lines\n    to the black line\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#ENTER YOUR ATTEMPT AND THOUGHTS HERE:\n# A1: SD of the distance between each toy type line intercepts to the black line intercept\n# A2: SD of the residuals, how far away each point is to the corresponding toyt type line\n# A3: intercept of the thick black line\n# A4: slope of the thick black line\n```\n:::\n\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-3' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\n::::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/match_summ1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n:::::\n\n-   **A1** = the standard deviation of the distances from all the\n    toy-type lines to the black line\\\n-   **A2** = the standard deviation of the distances from all the\n    individual datapoints (toys) to their respective toy-type lines\\\n-   **A3** = where the black line cuts the y axis\\\n-   **A4** = the slope of the black line\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Optional Extra</div><div class='question-body'>\n\n\n\nBelow is the model equation for the `ri_mod` model.\n\nIdentify the part of the equation that represents each of A1-4.\n\n:::::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/match_summ1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n\n:::: {.column width=\"50%\"}\n::: {style=\"font-size: .7em\"}\n\\begin{align}\n\\text{For Toy }j\\text{ of Type }i & \\\\\n\\text{Level 1 (Toy):}& \\\\\n\\text{R\\_AGE}_{ij} &= b_{0i} + b_1 \\cdot \\text{hrs\\_week}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Type):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\n:::\n::::\n::::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from:\n\n-   $\\sigma_{\\varepsilon}$\\\n-   $b_{1}$\\\n-   $\\sigma_{0}$\\\n-   $\\gamma_{00}$\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n \n\n<div class=\"solution-begin\"><button id='sol-start-4' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\n-   **A1 =** $\\sigma_{0}$\\\n-   **A2 =** $\\sigma_{\\varepsilon}$\\\n-   **A3 =** $\\gamma_{00}$\\\n-   **A4 =** $b_{1}$\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n::: {.divider .div-transparent .div-dot}\n:::\n\n# Audio Interference in Executive Functioning (Repeated Measures)\n\n::: lo\nThis next set are closer to conducting a real study. We have some data\nand a research question (below). The exercises will walk you through\ndescribing the data, then prompt you to think about how we might fit an\nappropriate model to address the research question, and finally task you\nwith having a go at writing up what you've done.\n:::\n\n\n\n\n\n\n\n\n\n::: frame\n**Data: Audio interference in executive functioning**\n\nThis data is from a simulated study that aims to investigate the\nfollowing research question:\n\n> How do different types of audio interfere with executive functioning,\n> and does this interference differ depending upon whether or not\n> noise-cancelling headphones are used?\n\n30 healthy volunteers each completed the\nSymbol Digit Modalities Test (SDMT) - a commonly used test to assess\nprocessing speed and motor speed - a total of 15 times. During the\ntests, participants listened to either no audio (5 tests), white noise\n(5 tests) or classical music (5 tests). Half the participants listened\nvia active-noise-cancelling headphones, and the other half listened via\nspeakers in the room. Unfortunately, lots of the tests were not\nadministered correctly, and so not every participant has the full 15\ntrials worth of data.\n\nThe data is available at\n<https://uoepsy.github.io/data/lmm_ef_sdmt.csv>.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"fptnpbqagc\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#fptnpbqagc table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#fptnpbqagc thead, #fptnpbqagc tbody, #fptnpbqagc tfoot, #fptnpbqagc tr, #fptnpbqagc td, #fptnpbqagc th {\n  border-style: none;\n}\n\n#fptnpbqagc p {\n  margin: 0;\n  padding: 0;\n}\n\n#fptnpbqagc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#fptnpbqagc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fptnpbqagc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fptnpbqagc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fptnpbqagc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fptnpbqagc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fptnpbqagc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fptnpbqagc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fptnpbqagc .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#fptnpbqagc .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#fptnpbqagc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fptnpbqagc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fptnpbqagc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fptnpbqagc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fptnpbqagc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#fptnpbqagc .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fptnpbqagc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_left {\n  text-align: left;\n}\n\n#fptnpbqagc .gt_center {\n  text-align: center;\n}\n\n#fptnpbqagc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fptnpbqagc .gt_font_normal {\n  font-weight: normal;\n}\n\n#fptnpbqagc .gt_font_bold {\n  font-weight: bold;\n}\n\n#fptnpbqagc .gt_font_italic {\n  font-style: italic;\n}\n\n#fptnpbqagc .gt_super {\n  font-size: 65%;\n}\n\n#fptnpbqagc .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#fptnpbqagc .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#fptnpbqagc .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#fptnpbqagc .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#fptnpbqagc .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#fptnpbqagc .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#fptnpbqagc .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#fptnpbqagc .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#fptnpbqagc div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">PID</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Participant ID</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">audio</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Audio heard during the test ('no_audio', 'white_noise','music')</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">headphones</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Whether the participant listened via speakers (S) in the room or via noise cancelling headphones (H)</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">SDMT</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Symbol Digit Modalities Test (SDMT) score</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n:::\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n How many participants are there in the data?\\\nHow many have complete data (15 trials)?\\\nWhat is the average number of trials that participants completed? What\nis the minimum?\\\nDoes every participant have *some* data for each type of audio?\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nFunctions like `table()` and `count()` will likely be useful here.\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\nn_distinct(efdat$PID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n\n```{.r .cell-code}\ntrial_counts <- efdat %>% count(PID)\nsum(trial_counts$n == 15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(trial_counts$n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n\n```{.r .cell-code}\nmin(trial_counts$n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(efdat$PID, efdat$audio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        \n         music no_audio white_noise\n  PPT_01     4        5           4\n  PPT_02     5        4           3\n  PPT_03     3        2           5\n  PPT_04     3        4           3\n  PPT_05     5        2           3\n  PPT_06     4        4           5\n  PPT_07     4        3           4\n  PPT_08     4        4           5\n  PPT_09     5        4           5\n  PPT_10     4        5           4\n  PPT_11     4        4           4\n  PPT_12     4        5           5\n  PPT_13     4        4           3\n  PPT_14     3        5           4\n  PPT_15     4        5           4\n  PPT_16     4        4           3\n  PPT_17     5        4           5\n  PPT_18     5        3           3\n  PPT_19     3        5           3\n  PPT_20     4        4           5\n  PPT_21     3        5           4\n  PPT_22     4        4           3\n  PPT_23     3        3           4\n  PPT_24     4        5           5\n  PPT_25     4        4           5\n  PPT_26     5        4           5\n  PPT_27     5        2           4\n  PPT_28     4        4           4\n  PPT_29     4        4           4\n  PPT_30     2        5           3\n```\n\n\n:::\n\n```{.r .cell-code}\n# there are 30 participants, none of them have complete 15 traisl and the\n# average number of trials is 12 and min is 10. Yes every particpant have \n# some data for each type of audio\n```\n:::\n\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-5' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  1 - read in the data </button></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\nhead(efdat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  PID    audio       headphones  SDMT\n  <chr>  <chr>       <chr>      <dbl>\n1 PPT_15 no_audio    S             37\n2 PPT_22 no_audio    H             55\n3 PPT_21 no_audio    H             40\n4 PPT_20 no_audio    H             36\n5 PPT_20 no_audio    H             30\n6 PPT_05 white_noise S             30\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-6' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  2 - how many ppts?</button></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\nFor a quick \"how many?\", functions like `n_distinct()` can be handy:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn_distinct(efdat$PID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n:::\n\n\n\n\nWhich is essentially the same as asking:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunique(efdat$PID) |> length()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-7' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  3 - how many observations per ppt?</button></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\nHere are the counts of trials for each participant.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  count(PID)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 2\n  PID        n\n  <chr>  <int>\n1 PPT_01    13\n2 PPT_02    12\n3 PPT_03    10\n4 PPT_04    10\n5 PPT_05    10\n# ℹ 25 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe can pass that to something like `summary()` to get a quick\ndescriptive of the `n` column, and so we can see that no participant\ncompleted all 15 trials (max is 14). Everyone completed at least 10, and\nthe median was 12.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  count(PID) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     PID                  n     \n Length:30          Min.   :10  \n Class :character   1st Qu.:11  \n Mode  :character   Median :12  \n                    Mean   :12  \n                    3rd Qu.:13  \n                    Max.   :14  \n```\n\n\n:::\n:::\n\n\n\n\nWe could also do this easily with things like:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID) |> median()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-8' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  4 - how many observations for each audio type per ppt?</button></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\nFor this kind of thing I would typically default to using `table()` for\nsmaller datasets, to see how many datapoints are in each combination of\n`PID` and `audio`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID, efdat$audio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        \n         music no_audio white_noise\n  PPT_01     4        5           4\n  PPT_02     5        4           3\n  PPT_03     3        2           5\n  PPT_04     3        4           3\n  PPT_05     5        2           3\n  PPT_06     4        4           5\n  PPT_07     4        3           4\n  PPT_08     4        4           5\n  PPT_09     5        4           5\n  PPT_10     4        5           4\n  PPT_11     4        4           4\n  PPT_12     4        5           5\n  PPT_13     4        4           3\n  PPT_14     3        5           4\n  PPT_15     4        5           4\n  PPT_16     4        4           3\n  PPT_17     5        4           5\n  PPT_18     5        3           3\n  PPT_19     3        5           3\n  PPT_20     4        4           5\n  PPT_21     3        5           4\n  PPT_22     4        4           3\n  PPT_23     3        3           4\n  PPT_24     4        5           5\n  PPT_25     4        4           5\n  PPT_26     5        4           5\n  PPT_27     5        2           4\n  PPT_28     4        4           4\n  PPT_29     4        4           4\n  PPT_30     2        5           3\n```\n\n\n:::\n:::\n\n\n\n\nFrom the above, we can see that everyone has data from $\\geq 2$ trials\nfor a given audio type.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID, efdat$audio) |> min()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### a tidyverse way:\n\nWhen tables get too big, we can do the same thing with `count()`, but we\nneed to make sure that we are working with factors, in order to\nsummarise all possible combinations of groups (even empty ones)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  mutate(PID = factor(PID),\n         audio = factor(audio)) |>\n  # the .drop=FALSE means \"keep empty groups\"\n  count(PID,audio,.drop=FALSE) |> \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      PID             audio          n    \n PPT_01 : 3   music      :30   Min.   :2  \n PPT_02 : 3   no_audio   :30   1st Qu.:4  \n PPT_03 : 3   white_noise:30   Median :4  \n PPT_04 : 3                    Mean   :4  \n PPT_05 : 3                    3rd Qu.:5  \n PPT_06 : 3                    Max.   :5  \n (Other):72                               \n```\n\n\n:::\n:::\n\n\n\n\nThere are plenty of other ways (e.g., you could use combinations of\n`group_by()`, `summarise()`), so just pick one that makes sense to you.\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\n\n> How do different types of audio interfere with executive functioning,\n> and does this interference differ depending upon whether or not\n> noise-cancelling headphones are used?\n\nConsider the following questions about the study:\n\n-   What is our outcome of interest?\\\n    Executive functioning (SDMT)\n\n-   What variables are we seeking to investigate in terms of their\n    impact on the outcome?\\\n    Types of audio and headphones\n\n-   What are the units of observations?\\\n    individual traisl\n\n-   Are the observations clustered/grouped? In what way?\\\n    individuals\n\n-   What varies *within* these clusters?\\\n    audio type\n\n-   What varies *between* these clusters?\n\n    headphone types\n\n\n\n</div><p class=\"question-end\"></p>\n\n \n\n<div class=\"solution-begin\"><button id='sol-start-9' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\n-   What is our outcome of interest?\n    -   **SDMT scores**\\\n-   What variables are we seeking to investigate in terms of their\n    impact on the outcome?\n    -   **audio type** and the interaction **audio type** $\\times$\n        wearing headphones\n-   What are the units of observations?\n    -   **individual trials**\\\n-   What are the groups/clusters?\n    -   **participants**\\\n-   What varies *within* these clusters?\n    -   **the type of audio**\\\n-   What varies *between* these clusters?\n    -   **whether they listen via headphones or speakers**\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n Make factors and set the reference levels of the\n`audio` and `headphones` variables to \"no audio\" and \"speakers\"\nrespectively.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nCan't remember about setting factors and reference levels? Check back to\nUSMR!\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- efdat |>\n  mutate(\n    audio = fct_relevel(factor(audio), \"no_audio\"),\n    headphones = fct_relevel(factor(headphones), \"S\")\n  )\n```\n:::\n\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n \n\n<div class=\"solution-begin\"><button id='sol-start-10' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- efdat |>\n  mutate(\n    audio = fct_relevel(factor(audio), \"no_audio\"),\n    headphones = fct_relevel(factor(headphones), \"S\")\n  )\n```\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n Fit a multilevel model to address the aims of the\nstudy (copied below)\n\n> How do different types of audio interfere with executive functioning,\n> and does this interference differ depending upon whether or not\n> noise-cancelling headphones are used?\n\nSpecifying the model may feel like a lot, but try splitting it into\nthree parts:\n\n$$\n\\text{lmer(}\\overbrace{\\text{outcome }\\sim\\text{ fixed effects}}^1\\, + \\, (1 + \\underbrace{\\text{slopes}}_3\\, |\\, \\overbrace{\\text{grouping structure}}^2 )\n$$\n\n1.  Just like the `lm()`s we have used in the past, think about what we\n    want to *test*. This should provide the outcome and the structure of\n    our fixed effects.\\\n    fixed effects: SDMT \\~ audio \\* headphones\n\n2.  Think about how the observations are clustered/grouped. This should\n    tell us how to specify the grouping structure in the random\n    effects.\\\n    grouping structure -\\> PID\n\n3.  Think about which slopes (i.e. which terms in our fixed effects)\n    could feasibly vary between the clusters. This provides you with\n    what to put in as random slopes.\n\n    slopes -\\> audio, so at the end we have lmer(SDMT \\~ audio \\*\n    headphones + (1+audio\\|PID), data = efdata)\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nMake sure to read about multilevel modesl and how to fit them in\n[Chapter 2: MLM\n#multilevel-models-in-r](https://uoepsy.github.io/lmm/02_lmm.html#multilevel-models-in-r){target=\"_blank\"}.\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-11' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  1 - fixed effects</button></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\n\nThe question\\\n    \"*How do different types of audio interfere with executive\nfunctioning*\" means we are interested in the effects of audio type\n(`audio`) on executive functioning (`SDMT` scores), so we will want:\n\n```         \nlmer(SDMT ~ audio ...\n```\n\nHowever, the research aim also asks\\\n    \"*... and does this interference differ depending upon whether or\nnot noise-cancelling headphones are used?*\"\\\nwhich suggests that we are interested in the interaction\n`SDMT ~ audio * headphones`\n\n```         \nlmer(SDMT ~ audio * headphones + ...   \n```\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-12' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  2 - hierarchical data structure</button></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\n\nThere are lots of ways that our data is grouped.\\\nWe have:\n\n-   3 different groups of audio type\n    (no_audio, white_noise, music)\n-   2 groups of listening condition\n    (S, H)\n-   30 groups of participants (\"PPT_01\", \"PPT_02\", \"PPT_03\", ...)\n\nThe effects of audio type and headphones are both things we actually\nwant to *test* - these variables are in our fixed effects. The levels of\naudio and headphones are not just a random sample from a wider\npopulation of levels - they're a specific set of things we want to\ncompare SDMT scores between.\n\nCompare this with the participants - we don't care about if there is a\ndifference in SDMT scores between e.g., \"PPT_03\" and \"PPT_28\". The\nparticipants themselves are just a sample of people that we have taken\nfrom a wider population. This makes thinking of \"by-participant random\neffects\" a sensible approach - we model differences between participants\nas a normal distribution of deviations around some average:\n\n```         \nlmer(SDMT ~ audio * headphones + (1 + ... | PID)  \n```\n\nThe minimum that we can include is the random intercept. What `(1|PID)`\nspecifies is that \"participants vary in their SDMT scores\". This makes\nsense - we would expect some participants to have higher executive\nfunctioning (and so will tend to score high on the SDMT), and others to\nhave lower functioning (and so tend to score lower).\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-13' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-13', 'sol-start-13')\">  3 - random slopes</button></div><div class=\"solution-body\" id = \"sol-body-13\" style=\"display: none;\">\n\n\n\nWe can also include a random by-participant effect of `audio`.\\\n`audio|PID` specifies that the effect of audio type on SDMT varies by\nparticipant. This seems feasible - music might be very distracting (and\ninterfere a lot with the test) for some participants, but have a\nnegligible effect for others.\n\n```         \nlmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### Why can't we have `(headphones|PID)`?\n\nWhy can we fit `(1 + audio | PID)` but not `(1 + headphones | PID)`, or\nboth `(1 + audio + headphones | PID)` or\n`(1 + audio * headphones | PID)`?\n\nRemember that `y ~ ... + (x | g)` is saying \"the slope of y\\~x varies by\ng\".\\\nSuch a sentence only makes sense if each \"the slope of y\\~x\" is defined\nfor every (or most) groups.\n\nFor the `headphones` predictor, every participant is *either* in the \"S\"\n(speakers) condition *or* the \"H\" (headphones) condition.\\\nThis means that \"the effect of headphones on SDMT\" *doesn't exist* for\nany single participant! This means it makes no sense to try and think of\nthe effect as 'varying by participant'.\n\nCompare this to the `audio` predictor, for the effect *does* exist for a\nsingle given participant, therefore it is possible to think of it as\nbeing different for different participants (e.g. PPT_30's performance\nimproves with white noise, but PPT_16's performance does not).\n\nThe plots below may help to cement this idea:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-36-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-36-2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n We now have a model, but we don't have any\np-values or confidence intervals or anything - i.e. we have no\ninferential criteria on which to draw conclusions. There are a whole\nload of different methods available for drawing inferences from\nmultilevel models, which means it can be a bit of a never-ending rabbit\nhole. For now, we'll just use the 'quick and easy' approach provided by\nthe **lmerTest** package seen in the lectures.\n\nUsing the **lmerTest** package, re-fit your model, and you should now\nget some p-values!\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIf you use `library(lmerTest)` to load the package, then *every single*\nmodel you fit will show p-values calculated with the Satterthwaite\nmethod.\\\nPersonally, I would rather this is not the case, so I often opt to fit\nspecific models with these p-values without ever loading the package:\\\n`modp <- lmerTest::lmer(y ~ 1 + x + ....`\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdmt_mod <- lmerTest::lmer(SDMT ~ audio * headphones + (1 + audio | PID), data = efdat)\nsummary(sdmt_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: SDMT ~ audio * headphones + (1 + audio | PID)\n   Data: efdat\n\nREML criterion at convergence: 2376.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.34520 -0.62861  0.05762  0.60807  2.21250 \n\nRandom effects:\n Groups   Name             Variance Std.Dev. Corr       \n PID      (Intercept)      51.17    7.153               \n          audiomusic       13.69    3.700     0.03      \n          audiowhite_noise 15.22    3.901    -0.25 -0.16\n Residual                  31.49    5.612               \nNumber of obs: 360, groups:  PID, 30\n\nFixed effects:\n                             Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)                  33.25799    1.98897 28.22065  16.721 3.54e-16 ***\naudiomusic                   -8.01731    1.41149 27.58766  -5.680 4.58e-06 ***\naudiowhite_noise             -0.03044    1.44502 26.32588  -0.021 0.983354    \nheadphonesH                   6.85313    2.81170 28.19226   2.437 0.021355 *  \naudiomusic:headphonesH       -3.58748    2.00129 27.94011  -1.793 0.083875 .  \naudiowhite_noise:headphonesH  8.02458    2.04498 26.46166   3.924 0.000556 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) audmsc adwht_ hdphnH adms:H\naudiomusic  -0.174                            \naudiowht_ns -0.352  0.192                     \nheadphonesH -0.707  0.123  0.249              \nadmsc:hdphH  0.123 -0.705 -0.135 -0.173       \nadwht_ns:hH  0.249 -0.136 -0.707 -0.351  0.191\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: a model comparison\n\nIf we want to go down the model comparison route, we just need to\nisolate the relevant part(s) of the model that we are interested in.\n\nRemember, model comparison is sometimes a useful way of testing a *set*\nof coefficients. For instance, in this example the interaction involves\nestimating *two* terms: `audiomusic:headphonesH` and\n`audiowhite_noise:headphonesH`.\n\nTo test the interaction as a whole, we can create a model without the\ninteraction, and then compare it. The `SATmodcomp()` function from the\n**pbkrtest** package provides a way of conducting an F test with the\nsame Satterthwaite method of approximating the degrees of freedom:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdmt_mod <- lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\nsdmt_res <- lmer(SDMT ~ audio + headphones + \n                   (1 + audio | PID), data = efdat)\nlibrary(pbkrtest)\nSATmodcomp(largeModel = sdmt_mod, smallModel = sdmt_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlarge : SDMT ~ audio * headphones + (1 + audio | PID)\nsmall (restriction matrix) : \n                              \n 0 0 0 0  0.8936904 -0.4486841\n 0 0 0 0 -0.4486841 -0.8936904\n     statistic    ndf    ddf   p.value    \n[1,]    11.051  2.000 26.909 0.0003136 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-14' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-14', 'sol-start-14')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-14\" style=\"display: none;\">\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdmt_mod <- lmerTest::lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n\nsummary(sdmt_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: SDMT ~ audio * headphones + (1 + audio | PID)\n   Data: efdat\n\nREML criterion at convergence: 2376.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.34520 -0.62861  0.05762  0.60807  2.21250 \n\nRandom effects:\n Groups   Name             Variance Std.Dev. Corr       \n PID      (Intercept)      51.17    7.153               \n          audiomusic       13.69    3.700     0.03      \n          audiowhite_noise 15.22    3.901    -0.25 -0.16\n Residual                  31.49    5.612               \nNumber of obs: 360, groups:  PID, 30\n\nFixed effects:\n                             Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)                  33.25799    1.98897 28.22065  16.721 3.54e-16 ***\naudiomusic                   -8.01731    1.41149 27.58766  -5.680 4.58e-06 ***\naudiowhite_noise             -0.03044    1.44502 26.32588  -0.021 0.983354    \nheadphonesH                   6.85313    2.81170 28.19226   2.437 0.021355 *  \naudiomusic:headphonesH       -3.58748    2.00129 27.94011  -1.793 0.083875 .  \naudiowhite_noise:headphonesH  8.02458    2.04498 26.46166   3.924 0.000556 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) audmsc adwht_ hdphnH adms:H\naudiomusic  -0.174                            \naudiowht_ns -0.352  0.192                     \nheadphonesH -0.707  0.123  0.249              \nadmsc:hdphH  0.123 -0.705 -0.135 -0.173       \nadwht_ns:hH  0.249 -0.136 -0.707 -0.351  0.191\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\n\nWe've already seen in the example with the with the different types of\ntoys (above) that we can visualise the fitted values (model\npredictions). But these were plotting all the cluster-specific values,\nand what we are really interested in are the estimates of (and\nuncertainty around) our *fixed effects* (i.e. estimates for clusters *on\naverage*)\n\nUsing tools like the **effects** package can provide us with the values\nof the outcome across levels of a specific fixed predictor (holding\nother predictors at their mean).\n\nThis should get you started:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame() %>%\n  ggplot(aes(x=audio, y=fit, ymin=lower, ymax=upper, col=headphones)) +\n  geom_pointrange(size=1, lwd=1)\n```\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can see the effects package in [Chapter 2: MLM\n#visualising-models](https://uoepsy.github.io/lmm/02_lmm.html#visualising-models){target=\"_blank\"}.\nThe logic is just the same as it was for USMR, it's just that the\nestimated effects are from an `lmer()` instead of an `lm()`/`glm()`.\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n \n\n<div class=\"solution-begin\"><button id='sol-start-15' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-15', 'sol-start-15')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-15\" style=\"display: none;\">\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame() |>\n  ggplot(aes(x=audio,y=fit,\n             ymin=lower,ymax=upper,\n             col=headphones))+\n  geom_pointrange(size=1,lwd=1)\n```\n\n::: {.cell-output-display}\n![](MLM_Intro_Questions_files/figure-html/unnamed-chunk-41-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n Now we have some p-values and a plot, try to\ncreate a short write-up of the analysis and results.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThink about the principles that have guided you during write-ups thus\nfar.\n\nThe aim in writing a statistical report should be that a reader is able\nto more or less replicate your analyses **without** referring to your\nanalysis code. Furthermore, it should be able for a reader to understand\nand replicate your work *even if they use something other than R*. This\nrequires detailing all of the steps you took in conducting the analysis,\nbut without simply referring to R code.\n\n-   Provide a description of the sample that is used in the analysis,\n    and any steps that you took to get this sample (i.e. data\n    cleaning/removal)\n-   Describe the model/test and how it addresses the research question.\n    What is the structure of the model, and how did you get to this\n    model? *(You don't need a fancy model equation, you can describe in\n    words!)*.\n-   Present (visually and numerically) the key results of the\n    coefficient tests or model comparisons, and explain what these mean\n    in the context of the research question (this could be things like\n    practical significance of the effect size, and the group-level\n    variability in the effects).\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n \n\n<div class=\"solution-begin\"><button id='sol-start-16' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-16', 'sol-start-16')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-16\" style=\"display: none;\">\n\n\n\n::: imp\nSDMT scores were analyzed using linear mixed effects regression with\nfixed effects for audio type, headphone usage, and their interaction.\nRandom intercepts for participants and random slopes for audio type were\nincluded (SDMT \\~ audio \\* headphones + (1 + audio \\| PID)). Models were\nfitted using lme4 in R with p-values calculated via the Satterthwaite\nmethod. Audio type and headphone usage were treated as categorical\nvariables with reference levels set to \"no audio\" and \"speakers\"\nrespectively.\\\n\\\nThe model is used to address the question how different types of audio\ninterfere with executive functioning, and whether the interference\ndiffer depending upon whether or not noise-cancelling headphones are\nused. Here is the result after fitting the linear mixed effect model on\nthe data set: Participants using speakers with no audio scored an\naverage of 33.26 on the SDMT. Music through speakers significantly\ndecreased scores by 8.02 (p \\< 0.001), while white noise through\nspeakers had no significant effect (-0.03, p = 0.98). Headphones\nsignificantly improved baseline performance by 6.85 (p = 0.021). The\ninteraction between audio type and headphones showed that white noise\nthrough headphones was significantly more beneficial than through\nspeakers (interaction: +8.02, p \\< 0.001). Music remained detrimental\nregardless of delivery method, with a marginally greater negative effect\nthrough headphones (interaction: -3.59, p = 0.084). Individual\ndifferences were substantial (SD = 7.15 for baseline scores, SD = 3.70\nfor music effects, SD = 3.90 for white noise effects).\\\n\\\nThese findings show that the impact of audio on executive functioning\ndepends not only on the type of audio but also on how it is delivered.\nWhile music consistently impairs performance, white noise enhances it.\nBut only when listened to through noise-cancelling headphones.\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n::: int\nSDMT scores were modelled using linear mixed effects regression, with\nfixed effects of audio-type (no audio/white noise/music, treatment coded\nwith no audio as the reference level), audio delivery (speakers vs\nANC-headphones, treatment coded with speakers as the reference level)\nand their interaction. Participant-level random intercepts and random\nslopes of audio-type were also included. The inclusion of the\ninteraction term between audio-type and audio-delivery was used to\naddress the question of whether the interference of different audio on\nexecutive function depends on whether it is heard via noise-cancelling\nheadphones. A model comparison was conducted between the full model and\na restricted model that was identical to the full model with the\nexception that the interaction term was excluded. Models were fitted\nusing the **lme4** package in R, and estimated with restricted\nestimation maximum likelihood (REML). Denominator degrees of freedom for\nall comparisons and tests were approximated using the Satterthwaite\nmethod.\n\nInclusion of the interaction between headphones and audio-type was found\nto improve model fit ($F(2, 26.9) = 11.05, p < .001$), suggesting that\nthe interference of different types of audio on executive functioning is\ndependent upon whether the audio is presented through ANC-headphones or\nthrough speakers.\n\nParticipants not wearing headphones and presented with no audio scored\non average 33.26 on the SDMT. For participants without\nheadphones, listening to music via speakers was associated with lower\nscores compared to no audio\n($b = -8.02, t(27.59)=-5.68, p <0.001$), but\nthere was no significant difference between white noise and no audio.\n\nWith no audio playing, wearing ANC-headphones was associated with higher\nSDMT scores compared to those wearing no headphones\n($b = 6.85, t(28.19)=2.44, p =0.021$). The\napparent detrimental effect of music on SDMT scores was not\nsignificantly different in the headphones condition compared to the\nno-headphones condition\n($b = -3.59, t(27.94)=-1.79, p =0.084$).\nCompared to those listening through speakers, white noise was associated\nwith a greater increase in scores over no audio, when listening via\nANC-heaphones\n($b = 8.02, t(26.46)=3.92, p <0.001$).\n\nThere was considerable variability in baseline (i.e. no-audio) SDMT\nscores across participants (SD = 7.15), with participants\nshowing similar variability in the effects of music (SD = 3.7)\nand of white-noise (SD = 3.9). A weak negative correlation\n(-0.25) between participant-level intercepts and effects of\nwhite-noise indicated that people who score higher in the no-audio\ncondition tended to be more negatively effect by white-noise. A similar\nweak negative correlation (-0.16) between music and white-noise\neffects suggests participants who were more positively affected by one\ntype of audio tended to be more negatively affected by the other.\n\nThese results suggest that music appears to interfere with executive\nfunctioning (lower SDMT scores) compared to listening to no audio, and\nthis is not dependent upon whether is heard through headphones or\nspeakers. When listening via speakers, white noise was not associated\nwith differences in executive functioning compared to no audio, but this\nwas different for those listening via headphones, in which white noise\nsaw a greater increase in performance. Furthermore, there appear to be\nbenefits for executive functioning from wearing ANC-headphones even when\nnot-listening to audio, perhaps due to the noise cancellation. The\npattern of findings are displayed in @fig-efplot.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Interaction between the type (no audio/white noise/music) and the delivery (speakers/ANC headphones) on executive functioning task (SDMT)](MLM_Intro_Questions_files/figure-html/fig-efplot-1.png){#fig-efplot fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">SDMT</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Statistic</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">df</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">33.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">16.72</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">28.22</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">audio [music]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;8.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;5.68</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">27.59</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">audio [white_noise]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.983</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">26.33</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">headphones [H]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">6.85</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.44</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.021</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">28.19</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">audio [music] ×<br>headphones [H]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.59</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.79</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.084</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">27.94</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">audio [white_noise] ×<br>headphones [H]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.92</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">26.46</td>\n</tr>\n<tr>\n<td colspan=\"5\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">31.49</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>PID</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">51.17</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>11</sub> <sub>PID.audiomusic</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">13.69</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>11</sub> <sub>PID.audiowhite_noise</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">15.22</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&rho;<sub>01</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.03</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">-0.25</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.64</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>PID</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">30</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">360</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.392 / 0.783</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n::: {.divider .div-transparent .div-dot}\n:::\n",
    "supporting": [
      "MLM_Intro_Questions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/panelset-0.3.0/panelset.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/panelset-0.3.0/panelset.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}